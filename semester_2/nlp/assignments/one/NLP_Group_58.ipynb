{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq4pFpBt+mvq5goxIwvrtp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vatsaaa/mtech/blob/main/semester_2/nlp/assignments/one/NLP_Group_58.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group members\n",
        "<table width=\"100%\">\n",
        "  <tr>\n",
        "    <th width=\"25%\">Name</th>\n",
        "    <th width=\"40%\">Email</th>\n",
        "    <th width=\"20%\">Student ID</th>\n",
        "    <th width=\"15%\">Contribution</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>G. Ankur Vatsa</td>\n",
        "    <td>2023aa05727@wilp.bits-pilani.ac.in</td>\n",
        "    <td>2023aa05727</td>\n",
        "    <td>100%</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Meet Soni</td>\n",
        "    <td>2023aa05655@wilp.bits-pilani.ac.in</td>\n",
        "    <td>2023aa05655</td>\n",
        "    <td>100%</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Kinjal Bhoiwala</td>\n",
        "    <td>2023aa05490@wilp.bits-pilani.ac.in</td>\n",
        "    <td>2023aa05490</td>\n",
        "    <td>100%</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Randhawane Santosh Baban</td>\n",
        "    <td>2023aa05828@wilp.bits-pilani.ac.in</td>\n",
        "    <td>2023aa05828</td>\n",
        "    <td>100%</td>\n",
        "  </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "7SxQpMSahAQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKuOaozujy2Y",
        "outputId": "324955b3-4d3b-4980-f54c-faed501a0b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg2GMbwme0A1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import ConditionalFreqDist, FreqDist\n",
        "import numpy as np\n",
        "from re import sub\n",
        "from collections import defaultdict\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def log_function_entry_exit(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        logging.info(f\"Entering {func.__name__}\")\n",
        "        try:\n",
        "            result = func(*args, **kwargs)\n",
        "            logging.info(f\"Exiting {func.__name__} with result {result}\")\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"Exception in {func.__name__}: {e}\")\n",
        "            raise\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@log_function_entry_exit\n",
        "def preprocess_corpus(corpus):\n",
        "    \"\"\"\n",
        "    Preprocesses the corpus text by cleaning, tokenizing, and lowercasing.\n",
        "\n",
        "    Args:\n",
        "    corpus: String containing the raw corpus text.\n",
        "\n",
        "    Returns:\n",
        "    A list of preprocessed tokens (words).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cleaned_text = sub(r'[^\\w\\s]', '', corpus)\n",
        "        tokens = word_tokenize(cleaned_text.lower())\n",
        "        logging.info(f\"Preprocessed {len(tokens)} tokens.\")\n",
        "        return tokens\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"Error in preprocess_corpus: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "wqh1Q3Zke9RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@log_function_entry_exit\n",
        "def build_bigram_model(tokens, smoothing_factor=1):\n",
        "    \"\"\"\n",
        "    Builds a bigram model from the preprocessed tokens with Laplace smoothing.\n",
        "\n",
        "    Args:\n",
        "        tokens: A list of preprocessed tokens (words).\n",
        "        smoothing_factor: The value to add for smoothing (default: 1).\n",
        "\n",
        "    Returns:\n",
        "        A ConditionalFreqDist object representing the bigram probabilities with smoothing.\n",
        "    \"\"\"\n",
        "    logging.info(\"Starting build_bigram_model\")\n",
        "    try:\n",
        "        bigrams = list(nltk.bigrams(tokens))\n",
        "        bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "        vocab = set(tokens)\n",
        "        vocab_size = len(vocab)\n",
        "\n",
        "        # Count bigrams with progress logging\n",
        "        num_bigrams = len(bigrams)\n",
        "        processed_bigrams = 0\n",
        "        for i, (w1, w2) in enumerate(bigrams):\n",
        "            bigram_counts[w1][w2] += 1\n",
        "            processed_bigrams += 1\n",
        "            if processed_bigrams % 10000 == 0:  # Log progress every 10000 bigrams\n",
        "                logging.info(f\"Processed {processed_bigrams}/{num_bigrams} bigrams ({processed_bigrams/num_bigrams:.2%})\")\n",
        "\n",
        "        # Apply smoothing and calculate probabilities\n",
        "        bigram_probs = defaultdict(lambda: defaultdict(float))\n",
        "        for w1 in bigram_counts:\n",
        "            total_count = sum(bigram_counts[w1].values()) + (smoothing_factor * vocab_size)\n",
        "            for w2 in vocab:\n",
        "                bigram_probs[w1][w2] = (bigram_counts[w1][w2] + smoothing_factor) / total_count\n",
        "                logging.debug(f\"Calculated probability: [{w1} -> {w2}]: {bigram_probs[w1][w2]}\")\n",
        "\n",
        "        return bigram_probs, vocab_size\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"Error in build_bigram_model: {e}\")\n",
        "        raise\n",
        "    finally:\n",
        "        logging.info(\"Exiting build_bigram_model\")"
      ],
      "metadata": {
        "id": "v6LQD8whfB75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@log_function_entry_exit\n",
        "def generate_sentence(bigram_model, start_word, max_length=20, unk_token=\"<UNK>\"):\n",
        "    \"\"\"\n",
        "    Generates a sentence using the bigram model.\n",
        "\n",
        "    Args:\n",
        "    bigram_model: A ConditionalFreqDist object representing the bigram probabilities.\n",
        "    start_word: The starting word for the sentence.\n",
        "    max_length: The maximum desired length of the sentence.\n",
        "    unk_token: The token to use for unknown words (default: \"<UNK>\").\n",
        "\n",
        "    Returns:\n",
        "    A generated sentence as a list of words.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        sentence = [start_word]\n",
        "        current_word = start_word\n",
        "        for _ in range(max_length):\n",
        "            next_word_probs = bigram_model[current_word]\n",
        "            if current_word not in bigram_model:\n",
        "                next_word = unk_token\n",
        "            else:\n",
        "                next_word = next_word_probs.max()\n",
        "            sentence.append(next_word)\n",
        "            current_word = next_word\n",
        "            if next_word in ['.', '!', '?']:\n",
        "                break\n",
        "        return sentence\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"Error in generate_sentence: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "eU0SqwLefaNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@log_function_entry_exit\n",
        "def evaluate_test_set(bigram_probs, test_set, vocab_size):\n",
        "    \"\"\"\n",
        "    Evaluates the model on a test set by calculating average and standard deviation\n",
        "    of sentence probabilities.\n",
        "\n",
        "    Args:\n",
        "    bigram_probs: A dictionary representing the bigram probabilities.\n",
        "    test_set: A list of preprocessed test sentences.\n",
        "    vocab_size: The size of the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "    A tuple containing the average and standard deviation of sentence probabilities.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        sentence_probs = []\n",
        "        for sentence in test_set:\n",
        "            if len(sentence) < 2:\n",
        "                logging.info(\"Skipping sentence with less than 2 words\")\n",
        "                continue\n",
        "\n",
        "            sentence_prob = 1.0\n",
        "            for i in range(1, len(sentence)):\n",
        "                second_word = sentence[i]\n",
        "                first_word = sentence[i - 1]\n",
        "                logging.debug(f\"Evaluating bigram: [{first_word} -> {second_word}]\")\n",
        "\n",
        "                cond_prob = bigram_probs[first_word].get(second_word, 1 / vocab_size)\n",
        "                sentence_prob *= cond_prob\n",
        "                logging.debug(f\"Conditional probability: {cond_prob}\")\n",
        "\n",
        "            sentence_probs.append(sentence_prob)\n",
        "            logging.info(f\"Sentence probability: {sentence_prob}\")\n",
        "\n",
        "        avg_prob = np.mean(sentence_probs)\n",
        "        std_dev = np.std(sentence_probs)\n",
        "\n",
        "        return avg_prob, std_dev\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"Error in evaluate_test_set: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "afWPBPvofdcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@log_function_entry_exit\n",
        "def build_trigram_model(tokens, smoothing_factor=1):\n",
        "    \"\"\"\n",
        "    Builds a trigram model from the preprocessed tokens with Laplace smoothing.\n",
        "\n",
        "    Args:\n",
        "    tokens: A list of preprocessed tokens (words).\n",
        "    smoothing_factor: The value to add for smoothing (default: 1).\n",
        "\n",
        "    Returns:\n",
        "    A ConditionalFreqDist object representing the trigram probabilities with smoothing.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        trigrams = list(nltk.trigrams(tokens))\n",
        "        trigram_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
        "        vocab = set(tokens)\n",
        "        vocab_size = len(vocab)\n",
        "\n",
        "        for w1, w2, w3 in trigrams:\n",
        "            trigram_counts[w1][w2][w3] += 1\n",
        "            logging.debug(f\"Trigram count [{w1} -> {w2} -> {w3}]: {trigram_counts[w1][w2][w3]}\")\n",
        "\n",
        "        trigram_probs = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
        "        for w1 in trigram_counts:\n",
        "            for w2 in trigram_counts[w1]:\n",
        "                total_count = sum(trigram_counts[w1][w2].values()) + (smoothing_factor * vocab_size)\n",
        "                for w3 in vocab:\n",
        "                    trigram_probs[w1][w2][w3] = (trigram_counts[w1][w2][w3] + smoothing_factor) / total_count\n",
        "                    logging.debug(f\"Trigram probability [{w1} -> {w2} -> {w3}]: {trigram_probs[w1][w2][w3]}\")\n",
        "\n",
        "        return trigram_probs, vocab_size\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"Error in build_trigram_model: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "RAA9aTkLfgW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_perplexity(bigram_probs, test_set, vocab_size):\n",
        "  \"\"\"\n",
        "  Calculates the perplexity of the model on a test set.\n",
        "\n",
        "  Args:\n",
        "    bigram_probs: A dictionary representing the bigram probabilities.\n",
        "    test_set: A list of preprocessed test sentences.\n",
        "    vocab_size: The size of the vocabulary.\n",
        "\n",
        "  Returns:\n",
        "    The perplexity of the model on the test set.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    total_prob = 1.0\n",
        "    for sentence in test_set:\n",
        "      if len(sentence) < 2:\n",
        "        continue\n",
        "      sentence_prob = 1.0\n",
        "      for i in range(1, len(sentence)):\n",
        "        second_word = sentence[i]\n",
        "        first_word = sentence[i - 1]\n",
        "        cond_prob = bigram_probs[first_word].get(second_word, 1 / vocab_size)\n",
        "        sentence_prob *= cond_prob\n",
        "      total_prob *= sentence_prob\n",
        "    perplexity = (vocab_size ** (1.0 / len(words_in_test_set))) / total_prob\n",
        "    return perplexity\n",
        "  except Exception as e:\n",
        "    logging.exception(f\"Error in calculate_perplexity: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "lfo434KNfl4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load English news corpus as a string\n",
        "try:\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/eng_news_2019_10K-sentences.txt\", \"r\") as f:\n",
        "        corpus = f.read()\n",
        "    logging.info(\"Corpus loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.exception(f\"Error reading corpus file: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "WYryhSHpfpPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the corpus\n",
        "tokens = preprocess_corpus(corpus)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "split_index = int(0.8 * len(tokens))\n",
        "train_tokens = tokens[:split_index]\n",
        "test_tokens = tokens[split_index:]\n",
        "logging.info(f\"Training set size: {len(train_tokens)}\")\n",
        "logging.info(f\"Test set size: {len(test_tokens)}\")"
      ],
      "metadata": {
        "id": "bK-o6POIfu8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the bigram model\n",
        "bigram_probs, vocab_size = build_bigram_model(train_tokens)"
      ],
      "metadata": {
        "id": "ZxAfDnBJfycw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 10 sentences\n",
        "for i in range(10):\n",
        "    try:\n",
        "        generated_sentence = generate_sentence(bigram_probs, \"the\", vocab_size)\n",
        "        logging.info(f\"Generated sentence {i+1}: {' '.join(generated_sentence)}\")\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"Error generating sentence: {e}\")"
      ],
      "metadata": {
        "id": "kZighZZKf1HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on provided test set (replace with your test set)\n",
        "test_set = [[\"the\", \"weather\", \"is\", \"sunny\"], [\"the\", \"economy\", \"is\", \"booming\"]]\n",
        "try:\n",
        "    avg_prob, std_dev = evaluate_test_set(bigram_probs, test_set, vocab_size)\n",
        "    logging.info(f\"Average Probability (Provided Test Set): {avg_prob}\")\n",
        "    logging.info(f\"Standard Deviation (Provided Test Set): {std_dev}\")\n",
        "except Exception as e:\n",
        "    logging.exception(f\"Error evaluating provided test set: {e}\")"
      ],
      "metadata": {
        "id": "pU26yhN6f3a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your own curated test set\n",
        "curated_test_set = [[\"artificial\", \"intelligence\", \"revolution\"]]\n",
        "try:\n",
        "    avg_prob, std_dev = evaluate_test_set(bigram_probs, curated_test_set, vocab_size)\n",
        "    logging.info(f\"Average Probability (Curated Test Set): {avg_prob}\")\n",
        "    logging.info(f\"Standard Deviation (Curated Test Set): {std_dev}\")\n",
        "except Exception as e:\n",
        "    logging.exception(f\"Error evaluating curated test set: {e}\")"
      ],
      "metadata": {
        "id": "qLw2XILOf5Q8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}